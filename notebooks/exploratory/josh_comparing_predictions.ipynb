{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Josh Combining Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Models\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor,\\\n",
    "RandomForestClassifier, BaggingClassifier, ExtraTreesRegressor, VotingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Transformers\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "# Modeling Evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Pipelines\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../src\")\n",
    "\n",
    "from model_evaluation import plot_confusion_matrix\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "np.random.seed(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Flatten\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout, Activation, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>txt_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>product_target hr tweet riseaustin dead need upgrade plugin station sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>know awesome ipadiphone product_target youll likely appreciate design also theyre give free t sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>wait product_target also sale sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>hope year festival isnt crashy year iphone product_target sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>great stuff fri sxsw marissa mayer product_target tim oreilly tech booksconferences amp matt mullenweg wordpress</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion  \\\n",
       "0      0.0   \n",
       "1      2.0   \n",
       "2      2.0   \n",
       "3      0.0   \n",
       "4      2.0   \n",
       "\n",
       "                                                                                                        txt_cleaned  \n",
       "0                                          product_target hr tweet riseaustin dead need upgrade plugin station sxsw  \n",
       "1                know awesome ipadiphone product_target youll likely appreciate design also theyre give free t sxsw  \n",
       "2                                                                                wait product_target also sale sxsw  \n",
       "3                                                    hope year festival isnt crashy year iphone product_target sxsw  \n",
       "4  great stuff fri sxsw marissa mayer product_target tim oreilly tech booksconferences amp matt mullenweg wordpress  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.read_csv('../../data/targeted_combined.csv')\n",
    "clean_df.dropna(inplace = True)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divides data into X and y, and then turns the model target labels into numerical format\n",
    "\n",
    "X = clean_df['txt_cleaned'].values.astype('U')\n",
    "y = clean_df['emotion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range = (1,2))\n",
    "\n",
    "X_train_vec = cv.fit_transform(X_train)\n",
    "X_test_vec = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(max_iter=1000)\n",
    "LR.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_file = open(\"../../src/final_model_targeted.pkl\", \"rb\") # \"rb\" means \"read as bytes\"\n",
    "LR = pickle.load(LR_file)\n",
    "LR_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6597664543524416"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_predictions = LR.predict(X_test_vec)\n",
    "accuracy_score(y_test, LR_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = list(X_train)\n",
    "X_test_list = list(X_test)\n",
    "\n",
    "\n",
    "X_train_corpus = []\n",
    "for tweet in X_train_list:\n",
    "    X_train_corpus.extend(tweet.split(' '))\n",
    "    \n",
    "X_train_unique = len(set(X_train_corpus))\n",
    "\n",
    "sequence_length = 100\n",
    "\n",
    "full_tokenizer = text.Tokenizer(num_words=X_train_unique)\n",
    "\n",
    "full_tokenizer.fit_on_texts(X_train_list)\n",
    "\n",
    "X_train_tokenized= full_tokenizer.texts_to_sequences(X_train_list)\n",
    "X_test_tokenized= full_tokenizer.texts_to_sequences(X_test_list)\n",
    "\n",
    "X_train_CNN = sequence.pad_sequences(X_train_tokenized, maxlen=sequence_length)\n",
    "X_test_CNN = sequence.pad_sequences(X_test_tokenized, maxlen=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = load_model('CNN_final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_predictions = np.argmax(CNN.predict(X_test_CNN), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN = load_model('BiLSTMsmall64.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_predictions = np.argmax(RNN.predict(X_test_CNN), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenting df and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame(X_test, columns = ['Tweets'])\n",
    "true_labels = y_test.reset_index(drop=True)\n",
    "LR_predictions = pd.DataFrame(LR_predictions, columns = ['LR Predictions'])\n",
    "CNN_predictions = pd.DataFrame(CNN_predictions, columns = ['CNN Predictions'])\n",
    "RNN_predictions = pd.DataFrame(RNN_predictions, columns = ['RNN Predictions'])\n",
    "\n",
    "compare_predictions = pd.concat([tweets, true_labels, LR_predictions, CNN_predictions, RNN_predictions], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = compare_predictions[['LR Predictions','CNN Predictions','RNN Predictions']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR Predictions</th>\n",
       "      <th>CNN Predictions</th>\n",
       "      <th>RNN Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5647</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5648</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5649</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5650</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5652 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LR Predictions  CNN Predictions  RNN Predictions\n",
       "0                  0                2                2\n",
       "1                  2                2                1\n",
       "2                  2                2                0\n",
       "3                  0                1                1\n",
       "4                  1                1                2\n",
       "...              ...              ...              ...\n",
       "5647               0                0                2\n",
       "5648               1                1                2\n",
       "5649               0                0                2\n",
       "5650               0                0                2\n",
       "5651               2                2                1\n",
       "\n",
       "[5652 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.0\n",
       "1       2.0\n",
       "2       2.0\n",
       "3       1.0\n",
       "4       1.0\n",
       "       ... \n",
       "5647    0.0\n",
       "5648    1.0\n",
       "5649    0.0\n",
       "5650    0.0\n",
       "5651    2.0\n",
       "Name: 0, Length: 5652, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_y_pred = y_pred.mode(axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5189313517338995"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(compare_predictions['emotion'],vote_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_predictions.to_csv('../../data/compare_top_model_predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating sample tweets for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets = pd.read_csv('../../data/judge-1377884607_tweet_product_company.csv',encoding = 'latin-1')\n",
    "sample_tweets.dropna(inplace = True)\n",
    "sample_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_X = sample_tweets['tweet_text']\n",
    "sample_vec = cv.transform(sample_X)\n",
    "sample_y = LR.predict(sample_vec)\n",
    "pred_samples = pd.concat([sample_tweets.reset_index(drop = True), \n",
    "                          pd.DataFrame(sample_y).reset_index(drop = True)], axis = 1)\n",
    "pred_samples.columns = ['tweets','product','true emotions','LR predicted emotions']\n",
    "pred_samples.loc[pred_samples['LR predicted emotions'] == 2.0, 'LR predicted emotions'] = 'Positive emotion'\n",
    "pred_samples.loc[pred_samples['LR predicted emotions'] == 1.0, 'LR predicted emotions'] = 'Neutral emotion'\n",
    "pred_samples.loc[pred_samples['LR predicted emotions'] == 0.0, 'LR predicted emotions'] = 'Negative emotion'\n",
    "pred_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_samples[(pred_samples['LR predicted emotions'] == 'Positive emotion') & \n",
    "             (pred_samples['true emotions'] == \n",
    "              'Positive emotion')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_samples[(pred_samples['LR predicted emotions'] == 'Negative emotion') & \n",
    "             (pred_samples['true emotions'] == \n",
    "              'Negative emotion')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_samples[(pred_samples['LR predicted emotions'] == 'Positive emotion') & \n",
    "             (pred_samples['true emotions'] == \n",
    "              'Negative emotion')].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct1 = pd.DataFrame(pred_samples.iloc[1,:]).T\n",
    "correct2 = pd.DataFrame(pred_samples.iloc[1143,:]).T\n",
    "wrong1 = pd.DataFrame(pred_samples.iloc[3251,:]).T\n",
    "export_samples = pd.concat([correct1,correct2,wrong1], axis = 0)\n",
    "export_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_samples.to_csv('../../data/presentation_sample_tweets.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
