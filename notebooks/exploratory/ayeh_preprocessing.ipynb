{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "import re\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "def product_target(string):\n",
    "    s = string.lower()\n",
    "    if s == 'no target':\n",
    "        return ''\n",
    "    elif s == 'ipad':\n",
    "        return 'ipad'\n",
    "    elif s == 'apple':\n",
    "        return 'apple'\n",
    "    elif s == 'ipad or iphone app':\n",
    "        return 'app'\n",
    "    elif s == 'iphone':\n",
    "        return 'iphone'\n",
    "    elif s == 'other apple product or service':\n",
    "        return ''\n",
    "    elif s == 'google':\n",
    "        return 'google'\n",
    "    elif s == 'other google product or service':\n",
    "        return ''\n",
    "    elif s == 'android':\n",
    "        return 'android'\n",
    "    elif s == 'android app':\n",
    "        return 'android'\n",
    "    else:\n",
    "        return 'Unknown target'\n",
    "\n",
    "def txt_clean(txt):\n",
    "    # takes in a string and returns a cleaned up string ready for count or tfidf vectorizing\n",
    "    sw = stopwords.words('english')\n",
    "    sw.extend(['link', 'rt', 'get'])\n",
    "    punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~“!#'\n",
    "    no_accents_re = re.compile('^[a-z]+$')\n",
    "    accents = ['á', 'â', 'ã', 'à', 'å', 'ª', 'ç', 'è', '¼', '¾', 'î', 'ï', 'ì', 'ó', 'ö', 'ð', 'ü', 'ù', 'û', 'ý']\n",
    "    twitter_re = re.compile('[@][a-zA-Z]*')\n",
    "    num_re = re.compile('^\\d+$')\n",
    "    \n",
    "    # splitting the text up into words\n",
    "    t = txt[0].split(' ')\n",
    "    # turning the words lowercase\n",
    "    t = [w.lower() for w in t]\n",
    "    # removing punctuation\n",
    "    t = [w.translate(w.maketrans('','', punctuation)) for w in t]\n",
    "    # removing @'s which are twitter jargon\n",
    "    t = [w for w in t if not twitter_re.match(w)]\n",
    "    # removing leftover numbers\n",
    "    t = [w for w in t if not num_re.match(w)]\n",
    "    # removing words with accents\n",
    "    t = [w for w in t if no_accents_re.match(w)]\n",
    "    # removing stop words and more twitter jargon\n",
    "    t = [w for w in t if w not in sw]\n",
    "    # change targets in string to 'product_target'\n",
    "    t = ['product_target' if w == product_target(txt[1]) else w for w in t]\n",
    "    # removing empty strings\n",
    "    t = [w for w in t if w]\n",
    "    # word lemmatizing\n",
    "    t = pos_tag(t)\n",
    "    t = [(w[0], get_wordnet_pos(w[1])) for w in t]\n",
    "    lem = WordNetLemmatizer()\n",
    "    if lem: t = [lem.lemmatize(w[0], w[1]) for w in t]\n",
    "    # joining all the strings together into one\n",
    "    return ' '.join(t)\n",
    "\n",
    "def emotion_label(string):\n",
    "    s = string\n",
    "    if s == 'Positive emotion':\n",
    "        return 2\n",
    "    elif s == 'No emotion toward brand or product':\n",
    "        return 1\n",
    "    elif s == 'Negative emotion':\n",
    "        return 0\n",
    "    else:\n",
    "        print('Unknown emotion')\n",
    "\n",
    "def df_clean(lem = True):\n",
    "    df = pd.read_csv('../../data/judge-1377884607_tweet_product_company.csv', encoding = 'latin1')\n",
    "    df.columns = ['text', 'product', 'emotion']\n",
    "    df = df[df['emotion'] != 'I can\\'t tell']\n",
    "    df.dropna(inplace = True)\n",
    "    print(df['product'].value_counts())\n",
    "    df['text_product'] = df.apply(lambda x: list([x['text'], x['product']]), axis = 1)\n",
    "    df['emotion'] = df['emotion'].map(emotion_label)\n",
    "    df['txt_cleaned'] = df['text_product'].apply(txt_clean)\n",
    "    df.drop(columns = ['text', 'product', 'text_product'], inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPad                               942\n",
      "Apple                              659\n",
      "iPad or iPhone App                 470\n",
      "Google                             429\n",
      "iPhone                             296\n",
      "Other Google product or service    292\n",
      "Android App                         81\n",
      "Android                             78\n",
      "Other Apple product or service      35\n",
      "Name: product, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>txt_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>product_target hr tweet riseaustin dead need u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>know awesome ipadiphone product_target youll l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>wait product_target also sale sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>hope year festival isnt crashy year iphone pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>great stuff fri sxsw marissa mayer product_tar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9077</th>\n",
       "      <td>2</td>\n",
       "      <td>pr guy convince switch back product_target gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9079</th>\n",
       "      <td>2</td>\n",
       "      <td>quotpapyrussort like ipadquot nice lol sxsw la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9080</th>\n",
       "      <td>0</td>\n",
       "      <td>diller say google tv quotmight run playstation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>2</td>\n",
       "      <td>ive always use camera iphone bc image stabiliz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>2</td>\n",
       "      <td>product_target everywhere sxsw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3282 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion                                        txt_cleaned\n",
       "0           0  product_target hr tweet riseaustin dead need u...\n",
       "1           2  know awesome ipadiphone product_target youll l...\n",
       "2           2                 wait product_target also sale sxsw\n",
       "3           0  hope year festival isnt crashy year iphone pro...\n",
       "4           2  great stuff fri sxsw marissa mayer product_tar...\n",
       "...       ...                                                ...\n",
       "9077        2  pr guy convince switch back product_target gre...\n",
       "9079        2  quotpapyrussort like ipadquot nice lol sxsw la...\n",
       "9080        0  diller say google tv quotmight run playstation...\n",
       "9085        2  ive always use camera iphone bc image stabiliz...\n",
       "9088        2                     product_target everywhere sxsw\n",
       "\n",
       "[3282 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divides data into X and y, and then turns the model target labels into numerical format\n",
    "\n",
    "X = df['txt_cleaned']\n",
    "y = df['emotion'].replace(to_replace = {'Positive emotion' : 0, 'Negative emotion' : 1, 'No emotion toward brand or product': 2})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.25)\n",
    "X_t, X_val, y_t, y_val = train_test_split(X, y, random_state = 42, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer:\n",
    "    def __init__(self, vec_type, ngram = (1,1)):\n",
    "        if type(ngram) is not tuple:\n",
    "            print('Unknown tuple, format should be (minimum n-gram, maximum n-gram)')\n",
    "            return False\n",
    "        \n",
    "        if vec_type == 'cv':\n",
    "            self.vec = CountVectorizer(ngram_range = ngram)\n",
    "        elif vec_type == 'tfidf':\n",
    "            self.vec = TfidfVectorizer(ngram_range = ngram)\n",
    "        else:\n",
    "            print('Unknown vectorizer type')\n",
    "            return False\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        self.vec.fit(X)\n",
    "\n",
    "    def transform(self, X, y):\n",
    "        X_vec = self.vec.transform(X)\n",
    "        X_vec = pd.DataFrame.sparse.from_spmatrix(X_vec)\n",
    "        X_vec.columns = sorted(self.vec.vocabulary_)\n",
    "        X_vec.set_index(y.index, inplace = True)\n",
    "        return X_vec\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        self.vec.fit(X)\n",
    "        X_vec = self.vec.transform(X)\n",
    "        X_vec = pd.DataFrame.sparse.from_spmatrix(X_vec)\n",
    "        X_vec.columns = sorted(self.vec.vocabulary_)\n",
    "        X_vec.set_index(y.index, inplace = True)\n",
    "        return X_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store      1113\n",
       "new         802\n",
       "austin      688\n",
       "launch      620\n",
       "app         598\n",
       "amp         550\n",
       "social      481\n",
       "circle      468\n",
       "popup       427\n",
       "today       422\n",
       "android     419\n",
       "open        359\n",
       "network     355\n",
       "go          350\n",
       "line        335\n",
       "via         321\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range = (1,1))\n",
    "X_t_vec = cv.fit_transform(X_t)\n",
    "X_t_vec  = pd.DataFrame.sparse.from_spmatrix(X_t_vec)\n",
    "X_t_vec.columns = sorted(cv.vocabulary_)\n",
    "X_t_vec.set_index(y_t.index, inplace=True)\n",
    "\n",
    "X_val_vec = cv.transform(X_val)\n",
    "X_val_vec  = pd.DataFrame.sparse.from_spmatrix(X_val_vec)\n",
    "X_val_vec.columns = sorted(cv.vocabulary_)\n",
    "X_val_vec.set_index(y_val.index, inplace=True)\n",
    "\n",
    "X_t_vec.sum(axis = 0).sort_values(ascending = False)[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "social network     338\n",
       "popup store        325\n",
       "new social         308\n",
       "network call       239\n",
       "call circle        222\n",
       "major new          220\n",
       "launch major       213\n",
       "temporary store    187\n",
       "possibly today     179\n",
       "circle possibly    170\n",
       "downtown austin    138\n",
       "ûï mention         134\n",
       "marissa mayer      132\n",
       "store downtown     132\n",
       "store austin       130\n",
       "open popup         121\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range = (2,2))\n",
    "X_t_vec = cv.fit_transform(X_t)\n",
    "X_t_vec  = pd.DataFrame.sparse.from_spmatrix(X_t_vec)\n",
    "X_t_vec.columns = sorted(cv.vocabulary_)\n",
    "X_t_vec.set_index(y_t.index, inplace=True)\n",
    "\n",
    "X_val_vec = cv.transform(X_val)\n",
    "X_val_vec  = pd.DataFrame.sparse.from_spmatrix(X_val_vec)\n",
    "X_val_vec.columns = sorted(cv.vocabulary_)\n",
    "X_val_vec.set_index(y_val.index, inplace=True)\n",
    "\n",
    "X_t_vec.sum(axis = 0).sort_values(ascending = False)[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new social network          288\n",
       "social network call         238\n",
       "major new social            219\n",
       "network call circle         215\n",
       "launch major new            213\n",
       "call circle possibly        168\n",
       "circle possibly today       168\n",
       "store downtown austin       117\n",
       "open temporary store        108\n",
       "temporary store downtown     77\n",
       "popup store austin           64\n",
       "open popup store             63\n",
       "open popup shop              56\n",
       "downtown austin launch       55\n",
       "launch new social            49\n",
       "rumor open temporary         48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range = (3,3))\n",
    "X_t_vec = cv.fit_transform(X_t)\n",
    "X_t_vec  = pd.DataFrame.sparse.from_spmatrix(X_t_vec)\n",
    "X_t_vec.columns = sorted(cv.vocabulary_)\n",
    "X_t_vec.set_index(y_t.index, inplace=True)\n",
    "\n",
    "X_val_vec = cv.transform(X_val)\n",
    "X_val_vec  = pd.DataFrame.sparse.from_spmatrix(X_val_vec)\n",
    "X_val_vec.columns = sorted(cv.vocabulary_)\n",
    "X_val_vec.set_index(y_val.index, inplace=True)\n",
    "\n",
    "X_t_vec.sum(axis = 0).sort_values(ascending = False)[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store      232.754934\n",
       "new        164.683823\n",
       "launch     151.630980\n",
       "austin     139.152442\n",
       "app        124.349935\n",
       "social     121.266819\n",
       "popup      117.843415\n",
       "circle     114.139122\n",
       "today      107.380222\n",
       "open       107.017833\n",
       "amp        104.570787\n",
       "network    103.692296\n",
       "via         90.282673\n",
       "line        87.238168\n",
       "call        85.940698\n",
       "go          80.454228\n",
       "dtype: float64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range = (1,1))\n",
    "X_t_vec = tfidf.fit_transform(X_t)\n",
    "X_t_vec = pd.DataFrame.sparse.from_spmatrix(X_t_vec)\n",
    "X_t_vec.columns = sorted(tfidf.vocabulary_)\n",
    "X_t_vec.set_index(y_t.index, inplace = True)\n",
    "\n",
    "X_val_vec = tfidf.transform(X_val)\n",
    "X_val_vec  = pd.DataFrame.sparse.from_spmatrix(X_val_vec)\n",
    "X_val_vec.columns = sorted(tfidf.vocabulary_)\n",
    "X_val_vec.set_index(y_val.index, inplace=True)\n",
    "\n",
    "X_t_vec.sum(axis = 0).sort_values(ascending = False)[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "social network     0.012871\n",
       "new social         0.012075\n",
       "popup store        0.011281\n",
       "network call       0.010188\n",
       "call circle        0.009623\n",
       "major new          0.009447\n",
       "launch major       0.009276\n",
       "possibly today     0.008182\n",
       "temporary store    0.008133\n",
       "circle possibly    0.007913\n",
       "store austin       0.006158\n",
       "downtown austin    0.005948\n",
       "open popup         0.005938\n",
       "store downtown     0.005905\n",
       "open temporary     0.005599\n",
       "ûï mention         0.004758\n",
       "dtype: float64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range = (2,2))\n",
    "X_t_vec = tfidf.fit_transform(X_t)\n",
    "X_t_vec = pd.DataFrame.sparse.from_spmatrix(X_t_vec)\n",
    "X_t_vec.columns = sorted(tfidf.vocabulary_)\n",
    "X_t_vec.set_index(y_t.index, inplace = True)\n",
    "\n",
    "X_val_vec = tfidf.transform(X_val)\n",
    "X_val_vec  = pd.DataFrame.sparse.from_spmatrix(X_val_vec)\n",
    "X_val_vec.columns = sorted(tfidf.vocabulary_)\n",
    "X_val_vec.set_index(y_val.index, inplace=True)\n",
    "\n",
    "X_t_vec.mean(axis = 0).sort_values(ascending = False)[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new social network          80.137694\n",
       "social network call         69.935329\n",
       "network call circle         65.313997\n",
       "major new social            64.712864\n",
       "launch major new            63.743781\n",
       "call circle possibly        54.022252\n",
       "circle possibly today       54.005559\n",
       "open temporary store        38.100215\n",
       "store downtown austin       36.312710\n",
       "temporary store downtown    27.969892\n",
       "popup store austin          24.687708\n",
       "open popup store            24.318210\n",
       "downtown austin launch      23.002409\n",
       "open popup shop             21.364177\n",
       "launch new social           20.361676\n",
       "rumor open temporary        19.746143\n",
       "dtype: float64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range = (3,3))\n",
    "X_t_vec = tfidf.fit_transform(X_t)\n",
    "X_t_vec = pd.DataFrame.sparse.from_spmatrix(X_t_vec)\n",
    "X_t_vec.columns = sorted(tfidf.vocabulary_)\n",
    "X_t_vec.set_index(y_t.index, inplace = True)\n",
    "\n",
    "X_val_vec = tfidf.transform(X_val)\n",
    "X_val_vec  = pd.DataFrame.sparse.from_spmatrix(X_val_vec)\n",
    "X_val_vec.columns = sorted(tfidf.vocabulary_)\n",
    "X_val_vec.set_index(y_val.index, inplace=True)\n",
    "\n",
    "X_t_vec.sum(axis = 0).sort_values(ascending = False)[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aapl</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abba</th>\n",
       "      <th>aber</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>abound</th>\n",
       "      <th>...</th>\n",
       "      <th>zlf</th>\n",
       "      <th>zms</th>\n",
       "      <th>zomb</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zynga</th>\n",
       "      <th>zzzs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3363</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5488</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6702 rows × 7507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aapl  aaron  ab  abacus  abba  aber  ability  able  abnormal  abound  \\\n",
       "3363     0      0   0       0     0     0        0     0         0       0   \n",
       "3204     0      0   0       0     0     0        0     0         0       0   \n",
       "4460     0      0   0       0     0     0        0     0         0       0   \n",
       "2311     0      0   0       0     0     0        0     0         0       0   \n",
       "6298     0      0   0       0     0     0        0     0         0       0   \n",
       "...    ...    ...  ..     ...   ...   ...      ...   ...       ...     ...   \n",
       "5837     0      0   0       0     0     0        0     0         0       0   \n",
       "5285     0      0   0       0     0     0        0     0         0       0   \n",
       "5488     0      0   0       0     0     0        0     0         0       0   \n",
       "873      0      0   0       0     0     0        0     0         0       0   \n",
       "7396     0      0   0       0     0     0        0     0         0       0   \n",
       "\n",
       "      ...  zlf  zms  zomb  zombie  zomg  zone  zoom  zuckerberg  zynga  zzzs  \n",
       "3363  ...    0    0     0       0     0     0     0           0      0     0  \n",
       "3204  ...    0    0     0       0     0     0     0           0      0     0  \n",
       "4460  ...    0    0     0       0     0     0     0           0      0     0  \n",
       "2311  ...    0    0     0       0     0     0     0           0      0     0  \n",
       "6298  ...    0    0     0       0     0     0     0           0      0     0  \n",
       "...   ...  ...  ...   ...     ...   ...   ...   ...         ...    ...   ...  \n",
       "5837  ...    0    0     0       0     0     0     0           0      0     0  \n",
       "5285  ...    0    0     0       0     0     0     0           0      0     0  \n",
       "5488  ...    0    0     0       0     0     0     0           0      0     0  \n",
       "873   ...    0    0     0       0     0     0     0           0      0     0  \n",
       "7396  ...    0    0     0       0     0     0     0           0      0     0  \n",
       "\n",
       "[6702 rows x 7507 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count or tfidf\n",
    "# n-gram range\n",
    "# data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
