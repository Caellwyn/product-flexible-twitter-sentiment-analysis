{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "src_path = pathlib.Path().absolute().parent.parent / \"src\"\n",
    "sys.path.append(str(src_path))\n",
    "\n",
    "import data_preprocessing as dp\n",
    "import model_evaluation as me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "import re\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Flatten\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout, Activation, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data using andrew's clean data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = dp.df_clean(lem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>txt_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>product_target hrs tweeting riseaustin dead ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>know awesome ipadiphone product_target youll l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>wait product_target also sale sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>hope years festival isnt crashy years iphone p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>great stuff fri sxsw marissa mayer product_tar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                        txt_cleaned\n",
       "0        0  product_target hrs tweeting riseaustin dead ne...\n",
       "1        2  know awesome ipadiphone product_target youll l...\n",
       "2        2                 wait product_target also sale sxsw\n",
       "3        0  hope years festival isnt crashy years iphone p...\n",
       "4        2  great stuff fri sxsw marissa mayer product_tar..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9077</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9079</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9080</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3282 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2\n",
       "0     1  0  0\n",
       "1     0  0  1\n",
       "2     0  0  1\n",
       "3     1  0  0\n",
       "4     0  0  1\n",
       "...  .. .. ..\n",
       "9077  0  0  1\n",
       "9079  0  0  1\n",
       "9080  1  0  0\n",
       "9085  0  0  1\n",
       "9088  0  0  1\n",
       "\n",
       "[3282 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(cleaned_df['emotion'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       product_target hrs tweeting riseaustin dead ne...\n",
       "1       know awesome ipadiphone product_target youll l...\n",
       "2                      wait product_target also sale sxsw\n",
       "3       hope years festival isnt crashy years iphone p...\n",
       "4       great stuff fri sxsw marissa mayer product_tar...\n",
       "                              ...                        \n",
       "9077    pr guy convinced switch back product_target gr...\n",
       "9079    quotpapyrussort like ipadquot nice lol sxsw la...\n",
       "9080    diller says google tv quotmight run playstatio...\n",
       "9085    ive always used camera iphone bc image stabili...\n",
       "9088                       product_target everywhere sxsw\n",
       "Name: txt_cleaned, Length: 3282, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cleaned_df['txt_cleaned']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "X_tr, X_v, y_tr, y_v = train_test_split(X_train, y_train, test_size=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenize tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = list(X_train)\n",
    "X_test_list = list(X_test)\n",
    "X_tr_list = list(X_tr)\n",
    "X_v_list = list(X_v)\n",
    "\n",
    "X_train_corpus = []\n",
    "X_tr_corpus = []\n",
    "for tweet in X_train_list:\n",
    "    X_train_corpus.extend(tweet.split(' '))\n",
    "for tweet in X_tr_list:\n",
    "    X_tr_corpus.extend(tweet.split(' '))\n",
    "    \n",
    "X_train_unique = len(set(X_train_corpus))\n",
    "X_tr_unique = len(set(X_tr_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequence_length = 100\n",
    "\n",
    "partial_tokenizer = text.Tokenizer(num_words=X_tr_unique)\n",
    "full_tokenizer = text.Tokenizer(num_words=X_train_unique)\n",
    "\n",
    "partial_tokenizer.fit_on_texts(X_tr_list)\n",
    "full_tokenizer.fit_on_texts(X_train_list)\n",
    "\n",
    "X_tr_tokenized = partial_tokenizer.texts_to_sequences(X_tr_list)\n",
    "X_v_tokenized = partial_tokenizer.texts_to_sequences(X_v_list)\n",
    "X_train_tokenized= full_tokenizer.texts_to_sequences(X_train_list)\n",
    "X_test_tokenized= full_tokenizer.texts_to_sequences(X_test_list)\n",
    "\n",
    "X_tr_tokens = sequence.pad_sequences(X_tr_tokenized, maxlen=sequence_length)\n",
    "X_v_tokens = sequence.pad_sequences(X_v_tokenized, maxlen=sequence_length)\n",
    "X_train_tokens = sequence.pad_sequences(X_train_tokenized, maxlen=sequence_length)\n",
    "X_test_tokens = sequence.pad_sequences(X_test_tokenized, maxlen=sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ^^^ modified for train_test_split variables up to here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct CNN with embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "partial_model = Sequential()\n",
    "\n",
    "embedding_size = 128\n",
    "partial_model.add(Embedding(input_dim=len(set(X_tr_corpus)), output_dim=embedding_size, input_length=sequence_length))\n",
    "partial_model.add(Conv1D(filters=32, kernel_size=4, activation='relu'))\n",
    "partial_model.add(Dropout(0.5))\n",
    "partial_model.add(MaxPooling1D(pool_size=2))\n",
    "partial_model.add(Flatten())\n",
    "partial_model.add(Dense(units=30, activation='tanh'))\n",
    "partial_model.add(Dense(units=3, activation='softmax'))\n",
    "partial_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit model on tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.5994 - accuracy: 0.7995 - val_loss: 0.4981 - val_accuracy: 0.8481\n",
      "Epoch 2/7\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.4688 - accuracy: 0.8202 - val_loss: 0.4072 - val_accuracy: 0.8650\n",
      "Epoch 3/7\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.2403 - accuracy: 0.9219 - val_loss: 0.4019 - val_accuracy: 0.8650\n",
      "Epoch 4/7\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.1317 - accuracy: 0.9529 - val_loss: 0.4269 - val_accuracy: 0.8819\n",
      "Epoch 5/7\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.0925 - accuracy: 0.9656 - val_loss: 0.5005 - val_accuracy: 0.8608\n",
      "Epoch 6/7\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.0704 - accuracy: 0.9765 - val_loss: 0.5406 - val_accuracy: 0.8481\n",
      "Epoch 7/7\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.0527 - accuracy: 0.9835 - val_loss: 0.5388 - val_accuracy: 0.8523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9d35628e10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_model.fit(X_tr_tokens, y_tr, validation_data=(X_v_tokens, y_v), epochs=7, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model on full train split for validation on 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = Sequential()\n",
    "\n",
    "embedding_size = 128\n",
    "full_model.add(Embedding(input_dim=len(set(X_train_corpus)), output_dim=embedding_size, input_length=sequence_length))\n",
    "full_model.add(Conv1D(filters=32, kernel_size=4, activation='relu'))\n",
    "full_model.add(Dropout(0.5))\n",
    "full_model.add(MaxPooling1D(pool_size=2))\n",
    "full_model.add(Flatten())\n",
    "full_model.add(Dense(units=30, activation='tanh'))\n",
    "full_model.add(Dense(units=3, activation='softmax'))\n",
    "full_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "83/83 [==============================] - 2s 20ms/step - loss: 0.5966 - accuracy: 0.8072 - val_loss: 0.5544 - val_accuracy: 0.8311\n",
      "Epoch 2/7\n",
      "83/83 [==============================] - 1s 17ms/step - loss: 0.4286 - accuracy: 0.8385 - val_loss: 0.4264 - val_accuracy: 0.8508\n",
      "Epoch 3/7\n",
      "83/83 [==============================] - 1s 17ms/step - loss: 0.2247 - accuracy: 0.9284 - val_loss: 0.4864 - val_accuracy: 0.8508\n",
      "Epoch 4/7\n",
      "83/83 [==============================] - 1s 18ms/step - loss: 0.1359 - accuracy: 0.9558 - val_loss: 0.5462 - val_accuracy: 0.8569\n",
      "Epoch 5/7\n",
      "83/83 [==============================] - 2s 19ms/step - loss: 0.1026 - accuracy: 0.9669 - val_loss: 0.5865 - val_accuracy: 0.8432\n",
      "Epoch 6/7\n",
      "83/83 [==============================] - 1s 18ms/step - loss: 0.0795 - accuracy: 0.9760 - val_loss: 0.6112 - val_accuracy: 0.8387\n",
      "Epoch 7/7\n",
      "83/83 [==============================] - 1s 18ms/step - loss: 0.0583 - accuracy: 0.9813 - val_loss: 0.7272 - val_accuracy: 0.8493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9d3732a0f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.fit(X_train_tokens, y_train, validation_data=(X_test_tokens, y_test), epochs=7, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
