{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "import re\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Flatten\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout, Activation, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/judge-1377884607_tweet_product_company.csv', encoding = 'latin1')\n",
    "df.columns = ['text', 'product', 'emotion']\n",
    "df = df[df['emotion'] != 'I can\\'t tell']\n",
    "df['product'].fillna('No Product', inplace = True)\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = pd.get_dummies(df['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative emotion</th>\n",
       "      <th>No emotion toward brand or product</th>\n",
       "      <th>Positive emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Negative emotion  No emotion toward brand or product  Positive emotion\n",
       "0                 1                                   0                 0\n",
       "1                 0                                   0                 1\n",
       "2                 0                                   0                 1\n",
       "3                 1                                   0                 0\n",
       "4                 0                                   0                 1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18955"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = [str(x) for x in list(df['text'])]\n",
    "\n",
    "corpus = []\n",
    "for tweet in text_list:\n",
    "    corpus.extend(tweet.split(' '))\n",
    "    \n",
    "len(set(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_list = [str(x) for x in list(df['text'])]\n",
    "tokenizer = text.Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(text_list)\n",
    "list_tokenized_text = tokenizer.texts_to_sequences(text_list)\n",
    "X_t = sequence.pad_sequences(list_tokenized_text, maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct CNN with embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "embedding_size = 128\n",
    "model.add(Embedding(input_dim=len(set(corpus)), output_dim=embedding_size, input_length=100))\n",
    "model.add(Conv1D(filters=32, kernel_size=4, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=30, activation='tanh'))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit model on tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "252/252 [==============================] - 9s 35ms/step - loss: 0.8114 - accuracy: 0.6124 - val_loss: 0.7427 - val_accuracy: 0.6387\n",
      "Epoch 2/7\n",
      "252/252 [==============================] - 8s 33ms/step - loss: 0.5957 - accuracy: 0.7457 - val_loss: 0.7099 - val_accuracy: 0.6633\n",
      "Epoch 3/7\n",
      "252/252 [==============================] - 8s 33ms/step - loss: 0.4050 - accuracy: 0.8401 - val_loss: 0.7726 - val_accuracy: 0.6465\n",
      "Epoch 4/7\n",
      "252/252 [==============================] - 9s 34ms/step - loss: 0.3069 - accuracy: 0.8834 - val_loss: 0.8015 - val_accuracy: 0.6622\n",
      "Epoch 5/7\n",
      "252/252 [==============================] - 8s 33ms/step - loss: 0.2518 - accuracy: 0.9021 - val_loss: 0.8266 - val_accuracy: 0.6723\n",
      "Epoch 6/7\n",
      "252/252 [==============================] - 9s 36ms/step - loss: 0.2202 - accuracy: 0.9126 - val_loss: 0.9046 - val_accuracy: 0.6667\n",
      "Epoch 7/7\n",
      "252/252 [==============================] - 9s 34ms/step - loss: 0.2083 - accuracy: 0.9159 - val_loss: 0.9278 - val_accuracy: 0.6566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa08ca5f6d8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_t, y, epochs=7, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
