{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "import re\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(context = 'notebook', style = 'whitegrid')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows',50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omg, I love the coding style here, so clean, so readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's split this notebook into EDA and Feature engineering, for clarity sake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering choices:\n",
    "1. combine all apple products into one (Is this legit for business question?)\n",
    "2. drop \"I can't tell\" (only lose a few rows, apparently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/judge-1377884607_tweet_product_company.csv', encoding = 'latin1')\n",
    "df.columns = ['text', 'target', 'emotion']\n",
    "\n",
    "df = df[df['emotion'] != 'I can\\'t tell'] #engineering choice\n",
    "df['target'].replace(['iPad', 'iPad or iPhone App', 'iPhone', 'Other Apple product or service'], \n",
    "                     'Apple', inplace = True) #engineering choice\n",
    "df['target'].replace(['Other Google product or service'], 'Google', inplace = True)\n",
    "df['target'].replace(['Android App'], 'Android', inplace = True)\n",
    "\n",
    "df['target'].fillna('No Target', inplace = True)\n",
    "df.dropna(inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting a lot of purely numeric, combination letter and numeric, and words starting with funky \"ui\" and \"uo\" beginnings, how can we filter those as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "sw.extend(['link', 'rt', 'sxsw'])\n",
    "punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~“!'\n",
    "twitter_re = re.compile('[#@][a-zA-Z]*')\n",
    "num_re = re.compile('^\\d{1}$')\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def txt_clean(txt, stop_words=sw):\n",
    "    t = txt.split(' ')\n",
    "    t = [w.lower() for w in t]\n",
    "    t = [w.translate(w.maketrans('','', punctuation)) for w in t]\n",
    "    t = [w for w in t if not twitter_re.match(w)]\n",
    "    t = [w for w in t if not num_re.match(w)]\n",
    "    t = [w for w in t if w not in stop_words]\n",
    "    t = [w for w in t if w]\n",
    "    t = pos_tag(t)\n",
    "    t = [(w[0], get_wordnet_pos(w[1])) for w in t]\n",
    "    lem = WordNetLemmatizer()\n",
    "    t = [lem.lemmatize(w[0], w[1]) for w in t]\n",
    "    return ' '.join(t)\n",
    "\n",
    "df['txt_cleaned'] = df['text'].map(txt_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['txt_cleaned']\n",
    "y = df['emotion']\n",
    "\n",
    "binarizer = LabelBinarizer()\n",
    "y = pd.DataFrame(binarizer.fit_transform(y), columns = binarizer.classes_)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   31,    1,   23],\n",
       "       [   0,    0,    0, ...,  184,  261,  697],\n",
       "       [   0,    0,    0, ...,  617, 1063,  413],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  117,  458, 3605],\n",
       "       [   0,    0,    0, ...,   99,  145,   40],\n",
       "       [   0,    0,    0, ...,    8, 2497,    3]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_len = 128\n",
    "\n",
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "list_tokenized_headlines = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = sequence.pad_sequences(list_tokenized_headlines, maxlen=100)\n",
    "\n",
    "tokenized_X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = sequence.pad_sequences(tokenized_X_test, maxlen=128)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  858, 1622, 4601],\n",
       "       [   0,    0,    0, ...,   86,  487, 3630],\n",
       "       [   0,    0,    0, ...,   18, 1964,   14],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   28,    1,   15],\n",
       "       [   0,    0,    0, ...,    2,    9,    7],\n",
       "       [   0,    0,    0, ...,   10,  618, 7072]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative emotion</th>\n",
       "      <th>No emotion toward brand or product</th>\n",
       "      <th>Positive emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6192</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6702 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Negative emotion  No emotion toward brand or product  Positive emotion\n",
       "3299                 0                                   0                 1\n",
       "3145                 0                                   1                 0\n",
       "4379                 0                                   0                 1\n",
       "2273                 0                                   0                 1\n",
       "6192                 0                                   0                 1\n",
       "...                ...                                 ...               ...\n",
       "5734                 0                                   1                 0\n",
       "5191                 0                                   0                 1\n",
       "5390                 0                                   1                 0\n",
       "860                  0                                   1                 0\n",
       "7270                 0                                   1                 0\n",
       "\n",
       "[6702 rows x 3 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index.keys())+1, sequence_len))\n",
    "model.add(LSTM(25, return_sequences=True))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 12s 86ms/step - loss: 0.9218 - acc: 0.5704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x247c0270490>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 1, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
